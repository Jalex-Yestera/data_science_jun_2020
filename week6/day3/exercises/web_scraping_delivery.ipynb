{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595506183833",
   "display_name": "Python 3.6.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From HTML\n",
    "\n",
    "*Using only beautiful soap*\n",
    "\n",
    "Save in a dataframe the next information using web scraping. Each row of the dataframe must have in different columns:\n",
    "\n",
    "- The name of the title\n",
    "- The id of the div where is the value scraped. If there is not id, then the value is must be numpy.nan\n",
    "- The name of the tag where is the value scraped.\n",
    "- The next scraped values in different rows: \n",
    "    - The value: \"Este es el segundo párrafo\"  --> Row 1\n",
    "    - The url https://pagina1.xyz/ --> Row 2\n",
    "    - The url https://pagina4.xyz/ --> Row 3\n",
    "    - The url https://pagina5.xyz/ --> Row 4\n",
    "    - The value \"links footer-links\" --> Row 5\n",
    "    - The value \"Este párrafo está en el footer\" --> Row 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"<html lang=\"es\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Página de prueba</title>\n",
    "</head>\n",
    "<body>\n",
    "<div id=\"main\" class=\"full-width\">\n",
    "    <h1>El título de la página</h1>\n",
    "    <p>Este es el primer párrafo</p>\n",
    "    <p>Este es el segundo párrafo</p>\n",
    "    <div id=\"innerDiv\">\n",
    "        <div class=\"links\">\n",
    "            <a href=\"https://pagina1.xyz/\">Enlace 1</a>\n",
    "            <a href=\"https://pagina2.xyz/\">Enlace 2</a>\n",
    "        </div>\n",
    "        <div class=\"right\">\n",
    "            <div class=\"links\">\n",
    "                <a href=\"https://pagina3.xyz/\">Enlace 3</a>\n",
    "                <a href=\"https://pagina4.xyz/\">Enlace 4</a>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"footer\">\n",
    "        <!-- El footer -->\n",
    "        <p>Este párrafo está en el footer</p>\n",
    "        <div class=\"links footer-links\">\n",
    "            <a href=\"https://pagina5.xyz/\">Enlace 5</a>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import smtplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['main', 'innerDiv', 'footer']"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "soup = BeautifulSoup(html)\n",
    "\n",
    "div_id = [re.search('\"\\w+\"', e).group()[1:-1] for e in re.findall(\"id=.*\",str(soup.contents[0]))]\n",
    "\n",
    "div_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Página de prueba'"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Get the title\n",
    "Titulo =soup.title.string\n",
    "Titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<p>Este es el segundo párrafo</p>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Get 2nd paragraph\n",
    "Seg_par = soup.findAll('p')[1]\n",
    "Seg_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['https://pagina1.xyz/',\n 'https://pagina2.xyz/',\n 'https://pagina3.xyz/',\n 'https://pagina4.xyz/',\n 'https://pagina5.xyz/']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Get all text between tags 'a' in a list\n",
    "Urls= soup.findAll('a')\n",
    "Lst_url =[]\n",
    "# Create for loop to put links in the list\n",
    "for url in Urls:\n",
    "    link = url.get('href')\n",
    "    Lst_url.append(link)\n",
    "Lst_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'links footer-links'"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "lista = re.findall(\"class=.*\",str(soup.contents[0]))\n",
    "Link_F = lista[4]\n",
    "Link_F = Link_F[7:-2]\n",
    "# print(lista)\n",
    "Link_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'Este párrafo está en el footer'"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Get 2nd paragraph\n",
    "Estepa = soup.findAll('p')[2].text\n",
    "Estepa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['p', 'p', 'a', 'a', 'a', 'a', 'p', 'a']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "a_tags= []\n",
    "for tag in soup.find_all(['a','p']):\n",
    "    a_tags.append(tag.name)\n",
    "a_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Página de prueba\nEste es el segundo párrafo\n['main', 'innerDiv', 'footer']\n['https://pagina1.xyz/', 'https://pagina2.xyz/', 'https://pagina3.xyz/', 'https://pagina4.xyz/', 'https://pagina5.xyz/']\nlinks footer-links\nEste párrafo está en el footer\n['p', 'p', 'a', 'a', 'a', 'a', 'p', 'a']\n"
    }
   ],
   "source": [
    "Values = [Seg_par.text, Lst_url[0], Lst_url[3], Lst_url[4] ]\n",
    "print(Titulo)\n",
    "print(Seg_par.text)\n",
    "print(div_id)\n",
    "print(Lst_url)\n",
    "print(Link_F)\n",
    "print(Estepa)\n",
    "print(a_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             Titulo    Div_id  Tag                           Value\n0  Página de prueba      main    p      Este es el segundo párrafo\n1  Página de prueba  innerDiv    a            https://pagina1.xyz/\n2  Página de prueba  innerDiv    a            https://pagina4.xyz/\n3  Página de prueba    footer    a            https://pagina5.xyz/\n4  Página de prueba    footer  Nan              links footer-links\n5  Página de prueba    footer    p  Este párrafo está en el footer",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Titulo</th>\n      <th>Div_id</th>\n      <th>Tag</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Página de prueba</td>\n      <td>main</td>\n      <td>p</td>\n      <td>Este es el segundo párrafo</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Página de prueba</td>\n      <td>innerDiv</td>\n      <td>a</td>\n      <td>https://pagina1.xyz/</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Página de prueba</td>\n      <td>innerDiv</td>\n      <td>a</td>\n      <td>https://pagina4.xyz/</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Página de prueba</td>\n      <td>footer</td>\n      <td>a</td>\n      <td>https://pagina5.xyz/</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Página de prueba</td>\n      <td>footer</td>\n      <td>Nan</td>\n      <td>links footer-links</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Página de prueba</td>\n      <td>footer</td>\n      <td>p</td>\n      <td>Este párrafo está en el footer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "data = {'Titulo': [Titulo, Titulo, Titulo, Titulo, Titulo, Titulo], 'Div_id':[ 'main', 'innerDiv','innerDiv','footer','footer','footer'], 'Tag':['p','a','a','a','Nan','p',],'Value':[Seg_par.text, Lst_url[0], Lst_url [3],Lst_url[4],Link_F,Estepa]}\n",
    "pd.DataFrame.from_dict(data)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. From Amazon\n",
    "\n",
    "*Using  beautiful soap and/or regex*\n",
    "\n",
    "Save in a dataframe the next information using web scraping. Using product pages from Amazon, do the following: \n",
    "\n",
    "- Get the product name from the web and save it in a column called \"item_name\"\n",
    "- Get the price from the web and save it in a column called \"item_price\"\n",
    "\n",
    "While you are doing the exercise, document the steps you are doing. Try to do the program for generic pages. If you cannot do it generic, explain the reasons. \n",
    "\n",
    "-------------------------------\n",
    "\n",
    "**Example:** \n",
    "\n",
    "url = https://www.amazon.es/Tommy-Hilfiger-UM0UM00054-Camiseta-Hombre/dp/B01MYD0T1F/ref=sr_1_1?dchild=1&pf_rd_p=58224bec-cac9-4dd2-a42a-61b1db609c2d&pf_rd_r=VZQ1JTQXFVRZ9E9VSKX4&qid=1595364419&s=apparel&sr=1-1\n",
    "\n",
    "*item_name* --> \"Tommy Hilfiger Logo Camiseta de Cuello Redondo,Perfecta para El Tiempo Libre para Hombre\"\n",
    "\n",
    "*item_price* --> [[18,99 € - 46,59 €]] or one of the options.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show beautiful html\n",
    "def show_html(html_str):\n",
    "\n",
    "    print(BeautifulSoup(str(html_str), 'html.parser').prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse Amazon to find something funny\n",
    "url = 'https://www.amazon.es/joven-haberte-comprado-sart%C3%A9n-antiadherente/dp/1640015426/ref=sr_1_20?dchild=1&keywords=libros+para+colorear+adultos&qid=1595668292&sr=8-20'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Un día eres joven y al otro eres feliz por haberte comprado una sartén antiadherente: Un libro de colorear para adultos: Amazon.es: Papeterie Bleu: Libros\n\n\n\n\n\n\n\n\n\n\n \n\n\nSelecciona Tus Preferencias de CookiesUtilizamos cookies y herramientas similares para mejorar tu experiencia de compra, prestar nuestros servicios, entender cómo los utilizas para poder mejorarlos, y para mostrarte anuncios. Terceros autorizados también utilizan estas herramientas en relación con los anuncios que mostramos.Se ha producido un problema al guardar tus preferencias de cookies. Inténtalo de nuevo.Aceptar cookiesPersonalizar cookies\n\n\n\n\nb[a]&amp;&amp;(a=f);return a}()},b=function(){return!!window.opera||!!window.opr&amp;&amp;!!window.opr.addons},d=function(){return!!document.documentMode},e=function(){return!d()&amp;&amp;\"undefined\"!==typeof CSS&amp;&amp;\nCSS.supports(\"(-ms-ime-align:auto)\")},k=function(){return\"webkit\"==c()},n=function(){return void 0!==r.chrome&amp;&amp;\"Opera Software ASA\"!=navigator.vendor&amp;&amp;void 0===navigator.msLaunchUri&amp;&amp;k()};return{isOpera:b,isIE:d,isEdge:e,isFirefox:function(){return\"undefined\"!==typeof InstallTrigger},isWebkit:k,isChrome:n,isSafari:function(){return!n()&amp;&amp;!e()&amp;&amp;!b()&amp;&amp;\"WebkitAppearance\"in document.documentElement.style}}}(),s=function(a,c,b,d){a.addEventListener?a.addEventListener(c,b,d):a.attachEvent&amp;&amp;a.attachEvent(\"on\"+\nc,b)},q=function(a,c,b,d){document.removeEventListener?a.removeEventListener(c,b,d||!1):document.detachEvent&amp;&amp;a.detachEvent(\"on\"+c,b)},y=function(a){var c;a=a.document;\"undefined\"!==typeof a.hidden?c=\"visibilitychange\":\"undefined\"!==typeof a.mozHidden?c=\"mozvisibilitychange\":\"undefined\"!==typeof a.msHidden?c=\"msvisibilitychange\":\"undefined\"!==typeof a.webkitHidden&amp;&amp;(c=\"webkitvisibilitychange\");return c},E=function(a,c){var b=y(a),d=a.document;b&amp;&amp;s(d,b,c,!1)},F=function(a){var c=window.addEventListener?\n\"addEventListener\":\"attachEvent\";(0,window[c])(\"attachEvent\"==c?\"onmessage\":\"message\",function(c){a(c[c.message?\"message\":\"data\"])},!1)},G=function(a,c){\"function\"===typeof a&amp;&amp;Math.random()\");e.close();var k=e.createElement(\"script\");k&amp;&amp;(k.type=\"text/javascript\",k.text=a,e.body.appendChild(k))}}catch(f){z(f,\"JS exception while injecting iframe\")}return d},z=function(a,c){f.ueLogError(a,{logLevel:\"ERROR\",attribution:\"A9TQForensics\",message:c})},I=function(a,c,b){a={vfrd:1===c?\"8\":\"4\",dbg:a};\"object\"===typeof b?a.info=JSON.stringify(b):\"string\"===typeof b&amp;&amp;(a.info=b);return{server:window.location.hostname,\nfmp:a}};(function(a){function c(a,c,b){var l=\"chrm msie ffox sfri opra phnt slnm othr extr xpcm invs poev njs cjs rhn clik1 rfs uam clik stln snd nfo hlpx clkh mmh chrm1 chrm2 wgl srvr zdim nomime chrm3 otch ivm.tst ivm.clk mmh2 clkh2 achf nopl\".split(\" \");r=ah-d)){b.push({x:a.clientX,y:a.clientY});if(50b.length))){var e=b[0].x,t=b[49].x,m=\nb[0].y,f=b[49].y;a=f-m;for(var k=e-t,e=m*t-e*f,t=b[49].ts-b[0].ts,m=!0,f=0;f&lt;b.length;f++)if(0!=a*b[f].x+k*b[f].y+e){m=!1;break}!0==m&amp;&amp;(a={grdt:a/k*-1,tmsp:t},l(),c(19,0,a))}d=h}},m=function(a){var d=a.clientX;a=a.clientY;var h={hcc:b.length,cx:d,cy:a};if(0===b.length)l(),c(18,0,h);else if(null!=d&amp;&amp;null!=a){var e;h.hpos=b;e=b[b.length-1];e=Math.sqrt(Math.pow(d-e.x,2)+Math.pow(a-e.y,2));100&lt;e&amp;&amp;(h.hcc=b.length,h.cx=d,h.cy=a,h.dhp=e,l(),c(15,0,h))}};s(a,\"mousemove\",e,!1);s(a,\"click\",m,!1)},B=function(){if(p.isFirefox()){var a=\n0;void 0!==window.onstorage&amp;&amp;a++;var b=document.createElement(\"div\");b.style.wordSpacing=\"22%\";\"22%\"===b.style.wordSpacing&amp;&amp;a++;\"function\"===typeof b.getAttributeNames&amp;&amp;a++;b=document.createElement(\"script\");b.type=\"text/javascript\";b.text=\"class Rectangle {             constructor(height, width) {                 this.height = height;                 this.width = width;             }             get area() {                 return this.calcArea();             }             calcArea() {                 return this.height * this.width;             }             }             const square = new Rectangle(10, 10);             window.__random__str = square.area;\";\ndocument.body.appendChild(b);100===window.__random__str&amp;&amp;a++;document.body.removeChild(b);2&lt;a&amp;&amp;(void 0===window.onabsolutedeviceorientation||void 0===navigator.permissions)&amp;&amp;c(37,0,a)}},v=function(){return null===navigator.userAgent.match(/(iPad|iPhone|iPod|android|webOS)/i)},C=function(){var a=function(a,b){for(var c,d=\"\",e={},h={},g=0,f=0;f&lt;b.length;f++)h[b[f]]=String.fromCharCode(126-f);var g=0,k;for(k in a)-1&lt;b.indexOf(k)&amp;&amp;(e[k]=1,g++);d=d+g+\"!\";if(\"function\"===typeof Object.getOwnPropertyNames){c=\nObject.getOwnPropertyNames(a);for(f=g=0;f&lt;c.length;f++)-1&lt;b.indexOf(c[f])&amp;&amp;(e[c[f]]=1,g++);d=d+g+\"!\"}if(\"function\"===typeof Object.keys){c=Object.keys(a);for(f=g=0;f&lt;c.length;f++)-1&lt;b.indexOf(c[f])&amp;&amp;(e[c[f]]=1,g++);d=d+g+\"!\"}if(\"prototype\"in Object&amp;&amp;\"hasOwnProperty\"in Object.prototype)for(k in e)Object.prototype.hasOwnProperty.call(e,k)&amp;&amp;(d+=h[k]);else for(k in e)d+=h[k];return encodeURIComponent(d)},b=document.createElement(\"nadu\"),a={w:a(window,\"SVGFESpotLightElement XMLHttpRequestEventTarget onratechange StereoPannerNode dolphinInfo VTTCue globalStorage WebKitCSSRegionRule MozSmsFilter MediaController mozInnerScreenX onwebkitwillrevealleft DOMMatrix GeckoActiveXObject MediaQueryListEvent PhoneNumberService ServiceWorkerContainer yandex vc2hxtaq9c NavigatorDeviceStorage HTMLHtmlElement ScreenOrientation MSGesture mozCancelRequestAnimationFrame GetSVGDocument MediaSource webkitMediaStream DeviceMotionEvent webkitPostMessage doNotTrack WebKitMediaKeyError HTMLCollection InstallTrigger StorageObsolete CustomEvent orientation XMLHttpRequest Worker showModelessDialog EventSource onmouseleave SVGAnimatedPathData TouchList TextTrackCue onanimationend HTMLBodyElement fluid MSFrameUITab Generator SecurityPolicyViolationEvent ClientRectList SmartCardEvent CSSSupportsRule mmbrowser\".split(\" \")),\nc:a(b.style,\"XvPhonemes MozTextAlignLast webkitFilter MozPerspective msTextSizeAdjust OAnimationFillMode borderImageSource MozOSXFontSmoothing border-inline-start-color MozOsxFontSmoothing columns touchAction scroll-snap-coordinate webkitAnimationFillMode webkitLineSnap webkitGridAutoColumns animationDuration isolation overflowWrap offsetRotation webkitShapeOutside MozOpacity position justifySelf borderRight webkitMatchNearestMailBlockquoteColor msImeAlign parentRule MozColumnFill cssText borderRightStyle textOverflow webkitGridRow webkitBackgroundComposite length -moz-column-fill enableBackground flex-basis\".split(\" \"))};\nf.ue&amp;&amp;f.ue.event&amp;&amp;(a={vfrd:\"0\",info:JSON.stringify(a)},f.ue.event({server:window.location.hostname,fmp:a},\"a9_tq\",\"a9_tq.FraudMetrics.3\"))};try{(a.callPhantom||a._phantom||a.PhantomEmitter||a.__phantomas||/PhantomJS/.test(navigator.userAgent))&amp;&amp;c(5);a.Buffer&amp;&amp;c(12);a.emit&amp;&amp;c(13);a.spawn&amp;&amp;c(14);(null!=a.domAutomation||null!=a.domAutomationController||null!=a._WEBDRIVER_ELEM_CACHE||/HeadlessChrome/.test(navigator.userAgent)||\"\"===navigator.languages)&amp;&amp;c(0);if(p.isChrome()&amp;&amp;a.webkitRequestFileSystem)a.webkitRequestFileSystem(a.TEMPORARY,\n1,function(){},function(){c(0)});else if(p.isSafari()&amp;&amp;a.localStorage){try{a.localStorage.setItem(\"__nadu\",\"\")}catch(J){c(3)}a.localStorage.removeItem(\"__nadu\")}!v()||navigator.mimeTypes&amp;&amp;0!=navigator.mimeTypes.length||(n?c(30,0,\"chrm\"):p.isFirefox()&amp;&amp;c(30,0,\"ff\"));p.isWebkit()&amp;&amp;n&amp;&amp;v()&amp;&amp;(void 0===a.chrome&amp;&amp;c(0),a.chrome&amp;&amp;a.chrome.app&amp;&amp;!1!==a.chrome.app.isInstalled&amp;&amp;void 0!==navigator.languages&amp;&amp;c(31));a.external&amp;&amp;\"function\"===typeof a.external.toString&amp;&amp;a.external.toString()&amp;&amp;-1&lt;a.external.toString().indexOf(\"RuntimeObject\")&amp;&amp;\nc(8);a.FirefoxInterfaces&amp;&amp;\"function\"===typeof a.FirefoxInterfaces&amp;&amp;a.FirefoxInterfaces(\"wdICoordinate\",\"wdIMouse\",\"wdIStatus\")&amp;&amp;c(2);a.XPCOMUtils&amp;&amp;c(9);(a.Components&amp;&amp;(a.Components.interfaces&amp;&amp;a.Components.interfaces.nsICommandProcessor||a.Components.wdICoordinate||a.Components.wdIMouse||a.Components.wdIStatus||a.Components.classes)||a.netscape&amp;&amp;a.netscape.security&amp;&amp;a.netscape.security.privilegemanager)&amp;&amp;c(8);a.isExternalUrlSafeForNavigation&amp;&amp;c(1);!a.opera||null===a.opera._browserjsran||0!==a.opera._browserjsran&amp;&amp;\n!1!==a.opera._browserjsran||c(4);a.screen&amp;&amp;(1&gt;=a.screen.availHeight||1&gt;=a.screen.availWidth||1&gt;=a.screen.height||1&gt;=a.screen.width||0&gt;=a.screen.devicePixelRatio)&amp;&amp;c(10);var w=window.setInterval(function(){var a=b();a.isSel&amp;&amp;(c(6,!0===a.isTest?1:0,a.info),window.clearInterval(w))},1E3);window.setTimeout(function(){window.clearInterval(w)},1E4);var x=a.PointerEvent;a.PointerEvent=function(){c(11);if(void 0!==x){var a=Array.prototype.slice.call(arguments);return new x(a)}return null};d();A(a);k();e();\n0!==a.outerHeight&amp;&amp;0!==a.outerWidth||c(29);B();!v()||navigator.plugins&amp;&amp;0!=navigator.plugins.length||(n?c(38,0,\"chrm\"):p.isFirefox()&amp;&amp;c(38,0,\"ff\"));G(C,10)}catch(D){z(D,\"JS exception - \")}})(r)})(ue_csm,window,document);\n\n\n\n\n\n\n\n\n\n\n}\n/* ◬ */\n\n"
    }
   ],
   "source": [
    "# Hacemos la sopa \n",
    "\n",
    "page = requests.get(url, headers={'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'})\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup\n",
    "show_html(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "html\nhead\nscript\nmeta\nscript\nmeta\nlink\nlink\nlink\nlink\nlink\nlink\nscript\nstyle\nscript\nstyle\nscript\nstyle\nlink\nstyle\nscript\nscript\nstyle\nstyle\nstyle\nscript\nmeta\nlink\nmeta\nmeta\nmeta\ntitle\nstyle\nscript\nstyle\nscript\nscript\nscript\nscript\nbody\ndiv\nscript\nscript\nimg\nscript\nspan\nform\ninput\ndiv\ni\ndiv\nh4\np\ndiv\ndiv\ni\ndiv\ndiv\nspan\nspan\ninput\nspan\nspan\nspan\na\nscript\nscript\nimg\nc\nhtml\nhead\ntitle\nbody\nl.length?l[a]:\"othr\";f.ue&&f.ue.event&&f.ue.event(i(r,c,b),\"a9_tq\",\"a9_tq.fraudmetrics.3\")}function\nb.length&&(b.shift(),!(50\nnoscript\nimg\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['html',\n 'head',\n 'script',\n 'meta',\n 'script',\n 'meta',\n 'link',\n 'link',\n 'link',\n 'link',\n 'link',\n 'link',\n 'script',\n 'style',\n 'script',\n 'style',\n 'script',\n 'style',\n 'link',\n 'style',\n 'script',\n 'script',\n 'style',\n 'style',\n 'style',\n 'script',\n 'meta',\n 'link',\n 'meta',\n 'meta',\n 'meta',\n 'title',\n 'style',\n 'script',\n 'style',\n 'script',\n 'script',\n 'script',\n 'script',\n 'body',\n 'div',\n 'script',\n 'script',\n 'img',\n 'script',\n 'span',\n 'form',\n 'input',\n 'div',\n 'i',\n 'div',\n 'h4',\n 'p',\n 'div',\n 'div',\n 'i',\n 'div',\n 'div',\n 'span',\n 'span',\n 'input',\n 'span',\n 'span',\n 'span',\n 'a',\n 'script',\n 'script',\n 'img',\n 'c',\n 'html',\n 'head',\n 'title',\n 'body',\n 'l.length?l[a]:\"othr\";f.ue&&f.ue.event&&f.ue.event(i(r,c,b),\"a9_tq\",\"a9_tq.fraudmetrics.3\")}function',\n 'b.length&&(b.shift(),!(50',\n 'noscript',\n 'img']"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Explore tags\n",
    "Tag_list = []\n",
    "for tag in soup.find_all(True):\n",
    "    Tag_list.append(tag.name)\n",
    "    print(tag.name)\n",
    "Tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "link = soup.find_all(id=\"productTitle\")\n",
    "#<span id=\"productTitle\" class=\"a-size-extra-large\">\n",
    "#Un día eres joven y al otro eres feliz por haberte comprado una sartén antiadherente: Un libro de colorear para adultos\n",
    "#</span>\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for child in soup.body.descendants:\n",
    "  #  print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'child' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ee02c885b5b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchild\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'child' is not defined"
     ]
    }
   ],
   "source": [
    "child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-196f1f56bdb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# necesitamos find mas ingredientes para la soup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"priceblock_ourprice\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "# necesitamos find mas ingredientes para la soup \n",
    "title = soup.find(id=\"Title\").get_text()\n",
    "price = soup.find(id=\"priceblock_ourprice\").get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echamos la url a la olla para hacer la sopa\n",
    "url = 'https://www.amazon.es/joven-haberte-comprado-sart%C3%A9n-antiadherente/dp/1640015426/ref=sr_1_20?dchild=1&keywords=libros+para+colorear+adultos&qid=1595668292&sr=8-20'\n",
    "\n",
    "def get_page_contents(url):\n",
    "    page = requests.get(url, headers={\"Accept-Language\": \"en-US\"})\n",
    "    return BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "sopita = get_page_contents(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "Product_name = sopita.find_all(id_='productTitle')\n",
    "Product_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_Text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b2853cef5205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"productTitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_Text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"priceblock_ourprice\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_Text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_Text'"
     ]
    }
   ],
   "source": [
    "# Encontré el ejercicio resuelto en towardsdatascience.\n",
    "# Importamos las librerías necesarias\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import smtplib\n",
    "\n",
    "# Relleno las headers con mis datos obtenidos usando xhaus\n",
    "headers = {\"User-agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
    "\n",
    "# Sustituyo la url por algo que mole\n",
    "url = 'https://www.amazon.de/gp/product/B0756CYWWD/ref=as_li_tl?ie=UTF8&tag=idk01e-21&camp=1638&creative=6742&linkCode=as2&creativeASIN=B0756CYWWD&linkId=18730d371b945bad11e9ea58ab9d8b32'\n",
    "\n",
    "\n",
    "# con requests nos traemos el contenido de la web con nuestras cabeceras\n",
    "page = requests.get(url, headers=headers)\n",
    "# hacemos la sopa\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "title = soup.find(id=\"productTitle\").get_Text()\n",
    "price = soup.find(id=\"priceblock_ourprice\").get_Text()\n",
    "sep = ','\n",
    "con_price = price.split(sep, 1)[0]\n",
    "converted_price = int(con_price.replace('.', ''))\n",
    "\n",
    "# price\n",
    "print(title.strip())\n",
    "print(converted_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-2a2c45873855>, line 9)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-29-2a2c45873855>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    url = 'soup = BeautifulSoup(page.content, 'html.parser')\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# Relleno las headers con mis datos obtenidos usando xhaus\n",
    "headers = {\"User-agent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36'}\n",
    "\n",
    "# Sustituyo la url por algo que mole\n",
    "url = 'soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    title = soup.find(id=\"productTitle\").get_text()\n",
    "    price = soup.find(id=\"priceblock_ourprice\").get_text()\n",
    "    sep = ','\n",
    "    con_price = price.split(sep, 1)[0]\n",
    "    converted_price = int(con_price.replace('.', ''))\n",
    "\n",
    "    # price\n",
    "    print(title.strip())\n",
    "    print(converted_price)\n",
    "\n",
    "amazon()'\n",
    "\n",
    "\n",
    "# con requests nos traemos el contenido de la web con nuestras cabeceras\n",
    "page = requests.get(url, headers=headers)\n",
    "# hacemos la sopa\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2d1e67d727a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverted_price\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mamazon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-2d1e67d727a6>\u001b[0m in \u001b[0;36mamazon\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"productTitle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"priceblock_ourprice\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "headers = {\n",
    "    \"User-agent\": 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'}\n",
    "\n",
    "URL = 'https://www.amazon.es/AmazonBasics-Paquete-100-pilas-alcalinas/dp/B01B8R6PF2?ref_=ast_sto_dp'\n",
    "def amazon():\n",
    "\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    title = soup.find(id=\"productTitle\").get_text()\n",
    "    price = soup.find(id=\"priceblock_ourprice\").get_text()\n",
    "    sep = ','\n",
    "    con_price = price.split(sep, 1)[0]\n",
    "    converted_price = int(con_price.replace('.', ''))\n",
    "\n",
    "    # price\n",
    "    print(title.strip())\n",
    "    print(converted_price)\n",
    "\n",
    "amazon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}